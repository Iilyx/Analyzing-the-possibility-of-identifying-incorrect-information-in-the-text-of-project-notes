{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Финальный результат (версия для параграфов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем необходимые библиотеки\n",
    "\n",
    "from docx import Document\n",
    "from docx.shared import RGBColor\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка данных из файла\n",
    "\n",
    "def load_data_from_docx(file_name):\n",
    "    document = Document(file_name)\n",
    "    words_to_delete=[\"Характеристики сооружения и основные решения\",\"Характеристики существующего сооружения и основные решения\",\"Мероприятия по обеспечению пожарной безопасности\",\"Антикоррозионная защита\",\"Таблица\"]\n",
    "    rez,found_start=[],False\n",
    "    for paragraph in document.paragraphs:\n",
    "        if 'Исходные данные' in paragraph.text:\n",
    "            found_start = True\n",
    "        elif found_start:\n",
    "            rez.append(paragraph.text)\n",
    "    return [i for i in rez if i.strip() and not any(word in i for word in words_to_delete)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_parts=load_data_from_docx(\"П-07.22-6.1-КР-ТЧ.docx\")\n",
    "#len(real_parts)\n",
    "#real_parts\n",
    "data = real_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# расстояние каждого предложения до других (значения + сортировка)\n",
    "\n",
    "def generate_seq_of_similarity_inc(data:list)->list:\n",
    "    results,results_values=[],[]\n",
    "    embedder = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "    for i in range(len(data)):\n",
    "        SENTENCE_NUM=i\n",
    "        sentence_embeddings = embedder.encode(data, convert_to_tensor=True)\n",
    "        given_sentence_embedding = sentence_embeddings[SENTENCE_NUM]\n",
    "        cosine_similarities_bert = util.pytorch_cos_sim(given_sentence_embedding.reshape(1, -1), sentence_embeddings).numpy().flatten()\n",
    "        results_values.append(cosine_similarities_bert)\n",
    "        results.append(cosine_similarities_bert.argsort())\n",
    "    return results,results_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "results,results_values=generate_seq_of_similarity_inc(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск \"непохожих\" предложений\n",
    "\n",
    "def get_frequence(results,results_values,isPrint=False):\n",
    "    sorts=[]\n",
    "    for j in range(len(results)):\n",
    "        sorts.append([i for i in results[j] if results_values[j][i]<np.mean(results_values)])\n",
    "    flat_arr = [val for arr in sorts for val in arr]\n",
    "    freq_dict = {val: flat_arr.count(val) for val in set(flat_arr)}\n",
    "    sorted_freq_list=sorted(freq_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    global data\n",
    "    data_stat=[i[1] for i in sorted_freq_list]\n",
    "    find,mark=[],False\n",
    "    if isPrint:\n",
    "        print(\"\\nЧастота встречаемости элементов (статистический анализ):\")\n",
    "        mark=True\n",
    "    for val, count in sorted_freq_list: \n",
    "        if count >= round(stat.mean(data_stat)+1.95*stat.stdev(data_stat)):\n",
    "            if mark:\n",
    "                print(f\"{val}: {count}\")\n",
    "                print(data[val])\n",
    "            find.append(data[val])\n",
    "            \n",
    "    return sorted_freq_list,find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_freq_list,find=get_frequence(results,results_values,False)\n",
    "#sorted_freq_list\n",
    "find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выгрузка результатов в отдельный файл\n",
    "\n",
    "def get_review(file_name,find):\n",
    "    document = Document(file_name)\n",
    "    # Список предложений, которые нужно выделить\n",
    "    sentences_to_highlight = find\n",
    "    # Проходим по всем абзацам в документе\n",
    "    for paragraph in document.paragraphs:\n",
    "        # Проверяем, содержит ли абзац какое-либо предложение из списка\n",
    "        for sentence in sentences_to_highlight:\n",
    "            if sentence in paragraph.text:\n",
    "                # Если предложение найдено, выделяем его\n",
    "                for run in paragraph.runs:\n",
    "                    if run.text in sentence:\n",
    "                        #run.font.color.rgb = RGBColor(255, 0, 0)\n",
    "                        run.font.highlight_color = WD_COLOR_INDEX.YELLOW\n",
    "\n",
    "    return document.save(f'{file_name}_review.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_review(\"П-07.22-6.1-КР-ТЧ.docx\",find)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do (pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
